# Hugging Face Token (get from https://huggingface.co/settings/tokens)
HF_TOKEN=your_token_here

# WandB API Key (optional, for experiment tracking)
WANDB_API_KEY=your_wandb_key_here
WANDB_PROJECT=enterprise-rag-llama3-qlora

# Model Configuration
BASE_MODEL=ibm-granite/granite-3.1-8b-instruct
# Alternative: meta-llama/Llama-3.1-8B-Instruct

# Training Configuration
OUTPUT_DIR=./outputs
MAX_SEQ_LENGTH=2048
BATCH_SIZE=4
GRADIENT_ACCUMULATION_STEPS=4
LEARNING_RATE=2e-4
NUM_EPOCHS=3

# Inference Configuration
VLLM_PORT=8000
FASTAPI_PORT=8080
